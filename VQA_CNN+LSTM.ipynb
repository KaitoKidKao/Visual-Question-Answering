{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OOSjmpMw5gxy"
   },
   "source": [
    "## 0. Download dataset\n",
    "**Note:** If you can't download using gdown due to limited number of downloads, please download it manually and upload it to your drive, then copy it from the drive to colab.\n",
    "```python\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "!cp /path/to/dataset/on/your/drive .\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "94MQBB3h9WT_",
    "outputId": "6cab9878-75b2-46dd-9ba4-60cf4c9864ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1kc6XNqHZJg27KeBuoAoYj70_1rT92191\n",
      "To: /content/vqa_coco_dataset.zip\n",
      "100% 196M/196M [00:02<00:00, 90.6MB/s]\n"
     ]
    }
   ],
   "source": [
    "# https://drive.google.com/file/d/1kc6XNqHZJg27KeBuoAoYj70_1rT92191/view?usp=sharing\n",
    "!gdown --id 1kc6XNqHZJg27KeBuoAoYj70_1rT92191"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "rb5Rh0fGAStN"
   },
   "outputs": [],
   "source": [
    "!unzip -q vqa_coco_dataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VljPGwOLCGoj"
   },
   "source": [
    "## 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "KDAACoro5r38"
   },
   "outputs": [],
   "source": [
    "!pip install timm -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchtext\n",
      "  Obtaining dependency information for torchtext from https://files.pythonhosted.org/packages/a8/a0/092d79d5cab3017cc98942509de22aceb30d9f91ee313dfe7bfd07e1bc63/torchtext-0.16.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading torchtext-0.16.2-cp311-cp311-win_amd64.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torchtext) (4.65.0)\n",
      "Requirement already satisfied: requests in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torchtext) (2.31.0)\n",
      "Collecting torch==2.1.2 (from torchtext)\n",
      "  Obtaining dependency information for torch==2.1.2 from https://files.pythonhosted.org/packages/e4/ae/2ad8820045b6631965750435f28583e80905b8273d57cf026163b51323ee/torch-2.1.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading torch-2.1.2-cp311-cp311-win_amd64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torchtext) (1.24.3)\n",
      "Collecting torchdata==0.7.1 (from torchtext)\n",
      "  Obtaining dependency information for torchdata==0.7.1 from https://files.pythonhosted.org/packages/da/8d/e0413f91944f931cb5c685cbd6330ad450f9d5466c466822d25761ca772d/torchdata-0.7.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading torchdata-0.7.1-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch==2.1.2->torchtext) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch==2.1.2->torchtext) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch==2.1.2->torchtext) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch==2.1.2->torchtext) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch==2.1.2->torchtext) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch==2.1.2->torchtext) (2023.4.0)\n",
      "Requirement already satisfied: urllib3>=1.25 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torchdata==0.7.1->torchtext) (1.26.16)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->torchtext) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->torchtext) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->torchtext) (2023.11.17)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tqdm->torchtext) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from jinja2->torch==2.1.2->torchtext) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from sympy->torch==2.1.2->torchtext) (1.3.0)\n",
      "Downloading torchtext-0.16.2-cp311-cp311-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.9 MB 991.0 kB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.2/1.9 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.5/1.9 MB 3.9 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.0/1.9 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/1.9 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 8.3 MB/s eta 0:00:00\n",
      "Downloading torch-2.1.2-cp311-cp311-win_amd64.whl (192.3 MB)\n",
      "   ---------------------------------------- 0.0/192.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/192.3 MB 52.2 MB/s eta 0:00:04\n",
      "    --------------------------------------- 2.5/192.3 MB 27.0 MB/s eta 0:00:08\n",
      "    --------------------------------------- 4.5/192.3 MB 31.8 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 6.8/192.3 MB 35.9 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 7.2/192.3 MB 38.0 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 8.7/192.3 MB 30.6 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 9.1/192.3 MB 32.1 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 10.9/192.3 MB 29.7 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 12.6/192.3 MB 32.7 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 13.4/192.3 MB 27.3 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 14.3/192.3 MB 27.3 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 15.1/192.3 MB 26.2 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 16.3/192.3 MB 23.4 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 16.7/192.3 MB 22.6 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 17.2/192.3 MB 21.1 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 17.6/192.3 MB 21.8 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 18.2/192.3 MB 19.3 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 18.4/192.3 MB 18.2 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 18.7/192.3 MB 17.3 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 19.0/192.3 MB 16.0 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 19.3/192.3 MB 14.9 MB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 19.6/192.3 MB 15.2 MB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 19.9/192.3 MB 13.9 MB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 20.2/192.3 MB 13.4 MB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 20.5/192.3 MB 12.8 MB/s eta 0:00:14\n",
      "   ---- ----------------------------------- 20.8/192.3 MB 12.1 MB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 21.1/192.3 MB 11.5 MB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 21.4/192.3 MB 11.1 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 21.7/192.3 MB 10.6 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 22.0/192.3 MB 10.2 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 22.3/192.3 MB 9.8 MB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 22.6/192.3 MB 9.4 MB/s eta 0:00:19\n",
      "   ---- ----------------------------------- 22.9/192.3 MB 9.4 MB/s eta 0:00:19\n",
      "   ---- ----------------------------------- 23.2/192.3 MB 9.1 MB/s eta 0:00:19\n",
      "   ---- ----------------------------------- 23.6/192.3 MB 8.8 MB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 23.9/192.3 MB 8.5 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 24.2/192.3 MB 8.3 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 24.5/192.3 MB 8.1 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 24.8/192.3 MB 7.9 MB/s eta 0:00:22\n",
      "   ----- ---------------------------------- 25.1/192.3 MB 7.7 MB/s eta 0:00:22\n",
      "   ----- ---------------------------------- 25.5/192.3 MB 7.6 MB/s eta 0:00:22\n",
      "   ----- ---------------------------------- 25.8/192.3 MB 7.4 MB/s eta 0:00:23\n",
      "   ----- ---------------------------------- 26.1/192.3 MB 7.3 MB/s eta 0:00:23\n",
      "   ----- ---------------------------------- 26.4/192.3 MB 7.0 MB/s eta 0:00:24\n",
      "   ----- ---------------------------------- 26.8/192.3 MB 7.0 MB/s eta 0:00:24\n",
      "   ----- ---------------------------------- 27.1/192.3 MB 7.0 MB/s eta 0:00:24\n",
      "   ----- ---------------------------------- 27.4/192.3 MB 6.9 MB/s eta 0:00:24\n",
      "   ----- ---------------------------------- 27.7/192.3 MB 6.7 MB/s eta 0:00:25\n",
      "   ----- ---------------------------------- 28.1/192.3 MB 6.7 MB/s eta 0:00:25\n",
      "   ----- ---------------------------------- 28.4/192.3 MB 6.7 MB/s eta 0:00:25\n",
      "   ----- ---------------------------------- 28.7/192.3 MB 6.8 MB/s eta 0:00:25\n",
      "   ------ --------------------------------- 29.1/192.3 MB 6.7 MB/s eta 0:00:25\n",
      "   ------ --------------------------------- 29.4/192.3 MB 6.7 MB/s eta 0:00:25\n",
      "   ------ --------------------------------- 29.7/192.3 MB 6.7 MB/s eta 0:00:25\n",
      "   ------ --------------------------------- 30.0/192.3 MB 6.8 MB/s eta 0:00:24\n",
      "   ------ --------------------------------- 30.4/192.3 MB 6.8 MB/s eta 0:00:24\n",
      "   ------ --------------------------------- 30.7/192.3 MB 6.8 MB/s eta 0:00:24\n",
      "   ------ --------------------------------- 31.0/192.3 MB 6.8 MB/s eta 0:00:24\n",
      "   ------ --------------------------------- 31.3/192.3 MB 6.9 MB/s eta 0:00:24\n",
      "   ------ --------------------------------- 31.7/192.3 MB 6.9 MB/s eta 0:00:24\n",
      "   ------ --------------------------------- 32.0/192.3 MB 6.9 MB/s eta 0:00:24\n",
      "   ------ --------------------------------- 32.3/192.3 MB 6.9 MB/s eta 0:00:24\n",
      "   ------ --------------------------------- 32.6/192.3 MB 6.9 MB/s eta 0:00:24\n",
      "   ------ --------------------------------- 33.0/192.3 MB 7.0 MB/s eta 0:00:23\n",
      "   ------ --------------------------------- 33.4/192.3 MB 7.0 MB/s eta 0:00:23\n",
      "   ------- -------------------------------- 33.7/192.3 MB 7.0 MB/s eta 0:00:23\n",
      "   ------- -------------------------------- 34.0/192.3 MB 7.0 MB/s eta 0:00:23\n",
      "   ------- -------------------------------- 34.4/192.3 MB 7.0 MB/s eta 0:00:23\n",
      "   ------- -------------------------------- 34.7/192.3 MB 7.0 MB/s eta 0:00:23\n",
      "   ------- -------------------------------- 35.1/192.3 MB 7.0 MB/s eta 0:00:23\n",
      "   ------- -------------------------------- 35.4/192.3 MB 7.0 MB/s eta 0:00:23\n",
      "   ------- -------------------------------- 35.8/192.3 MB 7.1 MB/s eta 0:00:23\n",
      "   ------- -------------------------------- 36.1/192.3 MB 7.1 MB/s eta 0:00:22\n",
      "   ------- -------------------------------- 36.4/192.3 MB 7.2 MB/s eta 0:00:22\n",
      "   ------- -------------------------------- 36.8/192.3 MB 7.2 MB/s eta 0:00:22\n",
      "   ------- -------------------------------- 37.2/192.3 MB 7.2 MB/s eta 0:00:22\n",
      "   ------- -------------------------------- 37.5/192.3 MB 7.2 MB/s eta 0:00:22\n",
      "   ------- -------------------------------- 37.9/192.3 MB 7.3 MB/s eta 0:00:22\n",
      "   ------- -------------------------------- 38.2/192.3 MB 7.2 MB/s eta 0:00:22\n",
      "   -------- ------------------------------- 38.6/192.3 MB 7.4 MB/s eta 0:00:21\n",
      "   -------- ------------------------------- 38.9/192.3 MB 7.4 MB/s eta 0:00:21\n",
      "   -------- ------------------------------- 39.3/192.3 MB 7.4 MB/s eta 0:00:21\n",
      "   -------- ------------------------------- 39.7/192.3 MB 7.4 MB/s eta 0:00:21\n",
      "   -------- ------------------------------- 40.0/192.3 MB 7.4 MB/s eta 0:00:21\n",
      "   -------- ------------------------------- 40.4/192.3 MB 7.4 MB/s eta 0:00:21\n",
      "   -------- ------------------------------- 40.8/192.3 MB 7.5 MB/s eta 0:00:21\n",
      "   -------- ------------------------------- 41.1/192.3 MB 7.5 MB/s eta 0:00:21\n",
      "   -------- ------------------------------- 41.5/192.3 MB 7.5 MB/s eta 0:00:21\n",
      "   -------- ------------------------------- 41.9/192.3 MB 7.6 MB/s eta 0:00:20\n",
      "   -------- ------------------------------- 42.3/192.3 MB 7.6 MB/s eta 0:00:20\n",
      "   -------- ------------------------------- 42.6/192.3 MB 7.6 MB/s eta 0:00:20\n",
      "   -------- ------------------------------- 43.0/192.3 MB 7.6 MB/s eta 0:00:20\n",
      "   --------- ------------------------------ 43.4/192.3 MB 7.7 MB/s eta 0:00:20\n",
      "   --------- ------------------------------ 43.8/192.3 MB 7.7 MB/s eta 0:00:20\n",
      "   --------- ------------------------------ 44.1/192.3 MB 7.8 MB/s eta 0:00:20\n",
      "   --------- ------------------------------ 44.5/192.3 MB 7.7 MB/s eta 0:00:20\n",
      "   --------- ------------------------------ 44.9/192.3 MB 7.7 MB/s eta 0:00:20\n",
      "   --------- ------------------------------ 45.3/192.3 MB 7.8 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 45.7/192.3 MB 7.9 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 46.0/192.3 MB 7.9 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 46.4/192.3 MB 7.9 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 46.8/192.3 MB 7.9 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 47.2/192.3 MB 7.9 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 47.6/192.3 MB 8.0 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 48.0/192.3 MB 7.9 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 48.4/192.3 MB 8.0 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 48.8/192.3 MB 8.0 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 49.2/192.3 MB 8.0 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 49.6/192.3 MB 8.2 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 50.0/192.3 MB 8.2 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 50.4/192.3 MB 8.2 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 50.7/192.3 MB 8.2 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 51.1/192.3 MB 8.2 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 51.5/192.3 MB 8.3 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 51.9/192.3 MB 8.3 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 52.3/192.3 MB 8.3 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 52.7/192.3 MB 8.3 MB/s eta 0:00:17\n",
      "   ----------- ---------------------------- 53.1/192.3 MB 8.3 MB/s eta 0:00:17\n",
      "   ----------- ---------------------------- 53.5/192.3 MB 8.4 MB/s eta 0:00:17\n",
      "   ----------- ---------------------------- 53.9/192.3 MB 8.4 MB/s eta 0:00:17\n",
      "   ----------- ---------------------------- 54.3/192.3 MB 8.4 MB/s eta 0:00:17\n",
      "   ----------- ---------------------------- 54.7/192.3 MB 8.4 MB/s eta 0:00:17\n",
      "   ----------- ---------------------------- 55.1/192.3 MB 8.4 MB/s eta 0:00:17\n",
      "   ----------- ---------------------------- 55.4/192.3 MB 8.3 MB/s eta 0:00:17\n",
      "   ----------- ---------------------------- 55.8/192.3 MB 8.4 MB/s eta 0:00:17\n",
      "   ----------- ---------------------------- 56.2/192.3 MB 8.4 MB/s eta 0:00:17\n",
      "   ----------- ---------------------------- 56.6/192.3 MB 8.4 MB/s eta 0:00:17\n",
      "   ----------- ---------------------------- 57.0/192.3 MB 8.4 MB/s eta 0:00:17\n",
      "   ----------- ---------------------------- 57.4/192.3 MB 8.4 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 57.8/192.3 MB 8.5 MB/s eta 0:00:16\n",
      "   ------------ --------------------------- 58.1/192.3 MB 8.3 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 58.4/192.3 MB 8.3 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 58.9/192.3 MB 8.4 MB/s eta 0:00:16\n",
      "   ------------ --------------------------- 59.2/192.3 MB 8.3 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 59.5/192.3 MB 8.2 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 59.8/192.3 MB 8.1 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 60.2/192.3 MB 8.1 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 60.5/192.3 MB 8.1 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 60.9/192.3 MB 8.1 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 61.2/192.3 MB 8.0 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 61.5/192.3 MB 7.9 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 61.8/192.3 MB 7.9 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 62.2/192.3 MB 7.9 MB/s eta 0:00:17\n",
      "   ------------- -------------------------- 62.5/192.3 MB 7.9 MB/s eta 0:00:17\n",
      "   ------------- -------------------------- 62.9/192.3 MB 7.8 MB/s eta 0:00:17\n",
      "   ------------- -------------------------- 63.3/192.3 MB 7.8 MB/s eta 0:00:17\n",
      "   ------------- -------------------------- 63.6/192.3 MB 7.8 MB/s eta 0:00:17\n",
      "   ------------- -------------------------- 64.0/192.3 MB 7.7 MB/s eta 0:00:17\n",
      "   ------------- -------------------------- 64.4/192.3 MB 7.8 MB/s eta 0:00:17\n",
      "   ------------- -------------------------- 64.8/192.3 MB 7.7 MB/s eta 0:00:17\n",
      "   ------------- -------------------------- 65.2/192.3 MB 7.7 MB/s eta 0:00:17\n",
      "   ------------- -------------------------- 65.6/192.3 MB 7.8 MB/s eta 0:00:17\n",
      "   ------------- -------------------------- 66.0/192.3 MB 7.8 MB/s eta 0:00:17\n",
      "   ------------- -------------------------- 66.4/192.3 MB 7.8 MB/s eta 0:00:17\n",
      "   ------------- -------------------------- 66.7/192.3 MB 7.7 MB/s eta 0:00:17\n",
      "   ------------- -------------------------- 67.1/192.3 MB 7.7 MB/s eta 0:00:17\n",
      "   -------------- ------------------------- 67.5/192.3 MB 7.7 MB/s eta 0:00:17\n",
      "   -------------- ------------------------- 67.9/192.3 MB 7.7 MB/s eta 0:00:17\n",
      "   -------------- ------------------------- 68.3/192.3 MB 7.8 MB/s eta 0:00:16\n",
      "   -------------- ------------------------- 68.7/192.3 MB 7.9 MB/s eta 0:00:16\n",
      "   -------------- ------------------------- 69.1/192.3 MB 7.8 MB/s eta 0:00:16\n",
      "   -------------- ------------------------- 69.5/192.3 MB 7.9 MB/s eta 0:00:16\n",
      "   -------------- ------------------------- 69.9/192.3 MB 8.0 MB/s eta 0:00:16\n",
      "   -------------- ------------------------- 70.3/192.3 MB 8.1 MB/s eta 0:00:16\n",
      "   -------------- ------------------------- 70.7/192.3 MB 8.1 MB/s eta 0:00:16\n",
      "   -------------- ------------------------- 71.1/192.3 MB 8.1 MB/s eta 0:00:15\n",
      "   -------------- ------------------------- 71.5/192.3 MB 8.3 MB/s eta 0:00:15\n",
      "   -------------- ------------------------- 72.0/192.3 MB 8.4 MB/s eta 0:00:15\n",
      "   --------------- ------------------------ 72.4/192.3 MB 8.4 MB/s eta 0:00:15\n",
      "   --------------- ------------------------ 72.9/192.3 MB 8.5 MB/s eta 0:00:15\n",
      "   --------------- ------------------------ 73.4/192.3 MB 8.5 MB/s eta 0:00:14\n",
      "   --------------- ------------------------ 73.8/192.3 MB 8.6 MB/s eta 0:00:14\n",
      "   --------------- ------------------------ 74.3/192.3 MB 8.8 MB/s eta 0:00:14\n",
      "   --------------- ------------------------ 74.8/192.3 MB 8.8 MB/s eta 0:00:14\n",
      "   --------------- ------------------------ 75.2/192.3 MB 9.0 MB/s eta 0:00:14\n",
      "   --------------- ------------------------ 75.7/192.3 MB 9.0 MB/s eta 0:00:14\n",
      "   --------------- ------------------------ 76.1/192.3 MB 9.1 MB/s eta 0:00:13\n",
      "   --------------- ------------------------ 76.6/192.3 MB 9.2 MB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 77.1/192.3 MB 9.2 MB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 77.6/192.3 MB 9.4 MB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 78.1/192.3 MB 9.5 MB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 78.6/192.3 MB 9.5 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 79.0/192.3 MB 9.6 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 79.5/192.3 MB 9.6 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 80.0/192.3 MB 9.8 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 80.4/192.3 MB 9.8 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 80.9/192.3 MB 9.9 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 81.4/192.3 MB 9.9 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 81.8/192.3 MB 9.9 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 82.3/192.3 MB 9.9 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 82.8/192.3 MB 9.9 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 83.2/192.3 MB 9.9 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 83.7/192.3 MB 10.1 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 84.3/192.3 MB 10.1 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 84.7/192.3 MB 10.1 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 85.2/192.3 MB 10.1 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 85.7/192.3 MB 10.1 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 86.2/192.3 MB 10.2 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 86.7/192.3 MB 10.2 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 87.2/192.3 MB 10.2 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 87.6/192.3 MB 10.2 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 88.2/192.3 MB 10.2 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 88.6/192.3 MB 10.2 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 89.2/192.3 MB 10.2 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 89.6/192.3 MB 10.2 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 90.1/192.3 MB 10.2 MB/s eta 0:00:10\n",
      "   ------------------ --------------------- 90.6/192.3 MB 10.4 MB/s eta 0:00:10\n",
      "   ------------------ --------------------- 91.1/192.3 MB 10.4 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 91.5/192.3 MB 10.2 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 92.0/192.3 MB 10.6 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 92.5/192.3 MB 10.6 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 93.1/192.3 MB 10.4 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 93.5/192.3 MB 10.6 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 94.0/192.3 MB 10.6 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 94.6/192.3 MB 10.6 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 95.0/192.3 MB 10.6 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 95.5/192.3 MB 10.6 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 96.1/192.3 MB 10.6 MB/s eta 0:00:10\n",
      "   -------------------- ------------------- 96.6/192.3 MB 10.7 MB/s eta 0:00:09\n",
      "   -------------------- ------------------- 97.0/192.3 MB 10.6 MB/s eta 0:00:10\n",
      "   -------------------- ------------------- 97.5/192.3 MB 10.6 MB/s eta 0:00:09\n",
      "   -------------------- ------------------- 98.0/192.3 MB 10.7 MB/s eta 0:00:09\n",
      "   -------------------- ------------------- 98.6/192.3 MB 10.7 MB/s eta 0:00:09\n",
      "   -------------------- ------------------- 99.1/192.3 MB 10.9 MB/s eta 0:00:09\n",
      "   -------------------- ------------------- 99.6/192.3 MB 10.7 MB/s eta 0:00:09\n",
      "   -------------------- ------------------ 100.2/192.3 MB 10.7 MB/s eta 0:00:09\n",
      "   -------------------- ------------------ 100.7/192.3 MB 10.9 MB/s eta 0:00:09\n",
      "   -------------------- ------------------ 101.2/192.3 MB 10.9 MB/s eta 0:00:09\n",
      "   -------------------- ------------------ 101.7/192.3 MB 10.9 MB/s eta 0:00:09\n",
      "   -------------------- ------------------ 102.2/192.3 MB 10.9 MB/s eta 0:00:09\n",
      "   -------------------- ------------------ 102.7/192.3 MB 10.9 MB/s eta 0:00:09\n",
      "   -------------------- ------------------ 103.2/192.3 MB 10.9 MB/s eta 0:00:09\n",
      "   --------------------- ----------------- 103.7/192.3 MB 10.9 MB/s eta 0:00:09\n",
      "   --------------------- ----------------- 104.3/192.3 MB 11.1 MB/s eta 0:00:08\n",
      "   --------------------- ----------------- 104.8/192.3 MB 11.1 MB/s eta 0:00:08\n",
      "   --------------------- ----------------- 105.4/192.3 MB 11.1 MB/s eta 0:00:08\n",
      "   --------------------- ----------------- 105.9/192.3 MB 11.1 MB/s eta 0:00:08\n",
      "   --------------------- ----------------- 106.4/192.3 MB 11.1 MB/s eta 0:00:08\n",
      "   --------------------- ----------------- 107.0/192.3 MB 11.1 MB/s eta 0:00:08\n",
      "   --------------------- ----------------- 107.5/192.3 MB 11.3 MB/s eta 0:00:08\n",
      "   --------------------- ----------------- 108.0/192.3 MB 11.3 MB/s eta 0:00:08\n",
      "   ---------------------- ---------------- 108.5/192.3 MB 11.3 MB/s eta 0:00:08\n",
      "   ---------------------- ---------------- 109.1/192.3 MB 11.3 MB/s eta 0:00:08\n",
      "   ---------------------- ---------------- 109.6/192.3 MB 11.3 MB/s eta 0:00:08\n",
      "   ---------------------- ---------------- 110.2/192.3 MB 11.3 MB/s eta 0:00:08\n",
      "   ---------------------- ---------------- 110.7/192.3 MB 11.3 MB/s eta 0:00:08\n",
      "   ---------------------- ---------------- 111.3/192.3 MB 11.3 MB/s eta 0:00:08\n",
      "   ---------------------- ---------------- 111.8/192.3 MB 11.3 MB/s eta 0:00:08\n",
      "   ---------------------- ---------------- 112.3/192.3 MB 11.3 MB/s eta 0:00:08\n",
      "   ---------------------- ---------------- 112.8/192.3 MB 11.5 MB/s eta 0:00:07\n",
      "   ---------------------- ---------------- 113.3/192.3 MB 11.5 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 113.9/192.3 MB 11.5 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 114.5/192.3 MB 11.5 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 115.0/192.3 MB 11.5 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 115.5/192.3 MB 11.5 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 116.1/192.3 MB 11.5 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 116.7/192.3 MB 11.7 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 117.2/192.3 MB 11.7 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 117.8/192.3 MB 11.7 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 118.4/192.3 MB 11.7 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 118.9/192.3 MB 11.7 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 119.5/192.3 MB 11.7 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 120.1/192.3 MB 11.9 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 120.7/192.3 MB 11.9 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 121.3/192.3 MB 11.9 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 121.8/192.3 MB 11.9 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 122.4/192.3 MB 12.1 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 123.0/192.3 MB 12.1 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 123.6/192.3 MB 12.4 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 124.3/192.3 MB 12.4 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 124.9/192.3 MB 12.6 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 125.5/192.3 MB 12.6 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 126.2/192.3 MB 12.6 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 126.8/192.3 MB 12.8 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 127.5/192.3 MB 12.8 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 128.1/192.3 MB 13.1 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 128.8/192.3 MB 13.1 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 129.5/192.3 MB 13.4 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 130.2/192.3 MB 13.6 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 130.8/192.3 MB 13.6 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 131.6/192.3 MB 13.9 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 132.3/192.3 MB 14.2 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 133.0/192.3 MB 14.2 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 133.7/192.3 MB 14.2 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 134.4/192.3 MB 14.6 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 135.1/192.3 MB 14.6 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 135.8/192.3 MB 14.9 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 136.6/192.3 MB 14.9 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 137.3/192.3 MB 14.9 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 138.0/192.3 MB 15.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 138.8/192.3 MB 15.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 139.5/192.3 MB 15.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 140.2/192.3 MB 15.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 140.2/192.3 MB 14.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 140.3/192.3 MB 14.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 140.4/192.3 MB 13.1 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 140.6/192.3 MB 12.4 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 141.0/192.3 MB 12.1 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 141.4/192.3 MB 11.5 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 141.9/192.3 MB 11.5 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 142.4/192.3 MB 11.3 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 143.0/192.3 MB 11.1 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 143.5/192.3 MB 10.9 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 144.0/192.3 MB 10.9 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 144.6/192.3 MB 10.7 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 145.1/192.3 MB 10.6 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 145.7/192.3 MB 10.6 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 146.4/192.3 MB 10.4 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 146.9/192.3 MB 10.4 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 147.5/192.3 MB 10.2 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 148.1/192.3 MB 10.1 MB/s eta 0:00:05\n",
      "   ------------------------------ --------- 148.6/192.3 MB 9.9 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 149.3/192.3 MB 9.9 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 149.9/192.3 MB 9.9 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 150.5/192.3 MB 10.2 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 151.1/192.3 MB 11.9 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 151.7/192.3 MB 12.1 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 152.3/192.3 MB 12.4 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 153.0/192.3 MB 12.6 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 153.6/192.3 MB 12.6 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 154.2/192.3 MB 12.8 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 154.9/192.3 MB 12.8 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 155.6/192.3 MB 13.1 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 156.4/192.3 MB 13.1 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 157.1/192.3 MB 13.1 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 157.7/192.3 MB 13.4 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 158.4/192.3 MB 13.4 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 159.1/192.3 MB 13.6 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 159.8/192.3 MB 13.6 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 160.4/192.3 MB 13.6 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 161.1/192.3 MB 13.9 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 161.8/192.3 MB 13.9 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 162.5/192.3 MB 14.2 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 163.1/192.3 MB 13.9 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 163.7/192.3 MB 13.9 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 164.4/192.3 MB 14.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 165.1/192.3 MB 14.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 165.8/192.3 MB 14.6 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 166.5/192.3 MB 14.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 167.2/192.3 MB 14.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 167.9/192.3 MB 14.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 168.7/192.3 MB 14.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 169.3/192.3 MB 14.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 170.1/192.3 MB 14.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 170.8/192.3 MB 14.5 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 171.5/192.3 MB 14.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 172.3/192.3 MB 14.9 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 173.0/192.3 MB 14.9 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 173.7/192.3 MB 14.9 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 174.4/192.3 MB 14.9 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 175.1/192.3 MB 15.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 175.9/192.3 MB 15.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 176.6/192.3 MB 15.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 177.3/192.3 MB 15.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 178.0/192.3 MB 15.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 178.7/192.3 MB 15.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 179.4/192.3 MB 15.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 180.2/192.3 MB 15.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 181.0/192.3 MB 15.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 181.7/192.3 MB 15.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 182.4/192.3 MB 15.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 183.1/192.3 MB 15.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 183.8/192.3 MB 15.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 184.4/192.3 MB 15.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 185.1/192.3 MB 15.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 185.7/192.3 MB 14.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 186.4/192.3 MB 14.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 187.2/192.3 MB 14.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  187.9/192.3 MB 14.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  188.6/192.3 MB 14.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  189.4/192.3 MB 14.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  190.2/192.3 MB 15.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  190.9/192.3 MB 15.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  191.7/192.3 MB 15.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 15.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 15.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 15.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 15.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 15.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 15.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 15.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 15.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 15.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 192.3/192.3 MB 8.5 MB/s eta 0:00:00\n",
      "Downloading torchdata-0.7.1-cp311-cp311-win_amd64.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.1/1.3 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.2/1.3 MB 2.3 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.3/1.3 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.4/1.3 MB 2.5 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.5/1.3 MB 2.3 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.7/1.3 MB 2.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 0.8/1.3 MB 2.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 0.9/1.3 MB 2.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 0.9/1.3 MB 2.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.1/1.3 MB 2.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.1/1.3 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.3/1.3 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.3/1.3 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 2.1 MB/s eta 0:00:00\n",
      "Installing collected packages: torch, torchdata, torchtext\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.1.1\n",
      "    Uninstalling torch-2.1.1:\n",
      "      Successfully uninstalled torch-2.1.1\n",
      "Successfully installed torch-2.1.2 torchdata-0.7.1 torchtext-0.16.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.16.1 requires torch==2.1.1, but you have torch 2.1.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Obtaining dependency information for spacy from https://files.pythonhosted.org/packages/90/f0/0133b684e18932c7bf4075d94819746cee2c0329f2569db526b0fa1df1df/spacy-3.7.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading spacy-3.7.2-cp311-cp311-win_amd64.whl.metadata (26 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Obtaining dependency information for spacy-loggers<2.0.0,>=1.0.0 from https://files.pythonhosted.org/packages/33/78/d1a1a026ef3af911159398c939b1509d5c36fe524c7b644f34a5146c4e16/spacy_loggers-1.0.5-py3-none-any.whl.metadata\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Obtaining dependency information for murmurhash<1.1.0,>=0.28.0 from https://files.pythonhosted.org/packages/71/46/af01a20ec368bd9cb49a1d2df15e3eca113bbf6952cc1f2a47f1c6801a7f/murmurhash-1.0.10-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading murmurhash-1.0.10-cp311-cp311-win_amd64.whl.metadata (2.0 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Obtaining dependency information for cymem<2.1.0,>=2.0.2 from https://files.pythonhosted.org/packages/c1/c3/dd044e6f62a3d317c461f6f0c153c6573ed13025752d779e514000c15dd2/cymem-2.0.8-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading cymem-2.0.8-cp311-cp311-win_amd64.whl.metadata (8.6 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Obtaining dependency information for preshed<3.1.0,>=3.0.2 from https://files.pythonhosted.org/packages/e4/fc/78cdbdb79f5d6d45949e72c32445d6c060977ad50a1dcfc0392622165f7c/preshed-3.0.9-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading preshed-3.0.9-cp311-cp311-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.3.0,>=8.1.8 (from spacy)\n",
      "  Obtaining dependency information for thinc<8.3.0,>=8.1.8 from https://files.pythonhosted.org/packages/74/24/564a7df5b1fac0520f6b55137deea2cc0b6f7d6e66228f1645dbfd59bb33/thinc-8.2.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading thinc-8.2.2-cp311-cp311-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Obtaining dependency information for wasabi<1.2.0,>=0.9.1 from https://files.pythonhosted.org/packages/8f/69/26cbf0bad11703241cb84d5324d868097f7a8faf2f1888354dac8883f3fc/wasabi-1.1.2-py3-none-any.whl.metadata\n",
      "  Downloading wasabi-1.1.2-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Obtaining dependency information for srsly<3.0.0,>=2.4.3 from https://files.pythonhosted.org/packages/eb/f5/e3f29993f673d91623df6413ba64e815dd2676fd7932cbc5e7347402ddae/srsly-2.4.8-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading srsly-2.4.8-cp311-cp311-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Obtaining dependency information for catalogue<2.1.0,>=2.0.6 from https://files.pythonhosted.org/packages/9e/96/d32b941a501ab566a16358d68b6eb4e4acc373fab3c3c4d7d9e649f7b4bb/catalogue-2.0.10-py3-none-any.whl.metadata\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.4.0,>=0.1.0 (from spacy)\n",
      "  Obtaining dependency information for weasel<0.4.0,>=0.1.0 from https://files.pythonhosted.org/packages/d5/e5/b63b8e255d89ba4155972990d42523251d4d1368c4906c646597f63870e2/weasel-0.3.4-py3-none-any.whl.metadata\n",
      "  Downloading weasel-0.3.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting typer<0.10.0,>=0.3.0 (from spacy)\n",
      "  Downloading typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "     ---------------------------------------- 0.0/45.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 45.9/45.9 kB 2.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (1.10.8)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (23.1)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "     ---------------------------------------- 0.0/181.6 kB ? eta -:--:--\n",
      "     ------------------------------------ - 174.1/181.6 kB 5.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- 181.6/181.6 kB 3.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (1.24.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.11.17)\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.1.8->spacy)\n",
      "  Obtaining dependency information for blis<0.8.0,>=0.7.8 from https://files.pythonhosted.org/packages/2f/09/da0592c74560cc33396504698122f7a56747c82a5e072ca7d2c3397898e1/blis-0.7.11-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading blis-0.7.11-cp311-cp311-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.3.0,>=8.1.8->spacy)\n",
      "  Obtaining dependency information for confection<1.0.0,>=0.0.1 from https://files.pythonhosted.org/packages/39/78/f9d18da7b979a2e6007bfcea2f3c8cc02ed210538ae1ce7e69092aed7b18/confection-0.1.4-py3-none-any.whl.metadata\n",
      "  Downloading confection-0.1.4-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.0.4)\n",
      "Collecting cloudpathlib<0.17.0,>=0.7.0 (from weasel<0.4.0,>=0.1.0->spacy)\n",
      "  Obtaining dependency information for cloudpathlib<0.17.0,>=0.7.0 from https://files.pythonhosted.org/packages/0f/6e/45b57a7d4573d85d0b0a39d99673dc1f5eea9d92a1a4603b35e968fbf89a/cloudpathlib-0.16.0-py3-none-any.whl.metadata\n",
      "  Downloading cloudpathlib-0.16.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n",
      "Downloading spacy-3.7.2-cp311-cp311-win_amd64.whl (12.1 MB)\n",
      "   ---------------------------------------- 0.0/12.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/12.1 MB 7.2 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.0/12.1 MB 10.2 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.3/12.1 MB 16.0 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.6/12.1 MB 20.8 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.6/12.1 MB 20.8 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 5.7/12.1 MB 20.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.6/12.1 MB 20.1 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 6.8/12.1 MB 20.6 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 6.9/12.1 MB 18.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.2/12.1 MB 19.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.1/12.1 MB 20.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.1/12.1 MB 20.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.1/12.1 MB 20.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.1/12.1 MB 20.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.1/12.1 MB 20.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.1/12.1 MB 20.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.1/12.1 MB 20.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.1/12.1 MB 20.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.8/12.1 MB 12.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.0/12.1 MB 12.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.1/12.1 MB 11.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.1/12.1 MB 10.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.2/12.1 MB 10.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.4/12.1 MB 10.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.7/12.1 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.1/12.1 MB 9.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.1/12.1 MB 9.1 MB/s eta 0:00:00\n",
      "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.8-cp311-cp311-win_amd64.whl (39 kB)\n",
      "Downloading murmurhash-1.0.10-cp311-cp311-win_amd64.whl (25 kB)\n",
      "Downloading preshed-3.0.9-cp311-cp311-win_amd64.whl (122 kB)\n",
      "   ---------------------------------------- 0.0/122.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 122.3/122.3 kB 7.0 MB/s eta 0:00:00\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.4.8-cp311-cp311-win_amd64.whl (479 kB)\n",
      "   ---------------------------------------- 0.0/479.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 479.7/479.7 kB 31.3 MB/s eta 0:00:00\n",
      "Downloading thinc-8.2.2-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ------------------------------- -------- 1.2/1.5 MB 37.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 31.3 MB/s eta 0:00:00\n",
      "Downloading wasabi-1.1.2-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.3.4-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.1/50.1 kB 2.5 MB/s eta 0:00:00\n",
      "Downloading blis-0.7.11-cp311-cp311-win_amd64.whl (6.6 MB)\n",
      "   ---------------------------------------- 0.0/6.6 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 1.4/6.6 MB 46.2 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 2.7/6.6 MB 34.3 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 2.8/6.6 MB 30.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 4.7/6.6 MB 27.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 5.9/6.6 MB 26.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.6/6.6 MB 26.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.6/6.6 MB 21.1 MB/s eta 0:00:00\n",
      "Downloading cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n",
      "   ---------------------------------------- 0.0/45.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 45.0/45.0 kB 2.2 MB/s eta 0:00:00\n",
      "Downloading confection-0.1.4-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, murmurhash, langcodes, cloudpathlib, catalogue, blis, typer, srsly, preshed, confection, weasel, thinc, spacy\n",
      "Successfully installed blis-0.7.11 catalogue-2.0.10 cloudpathlib-0.16.0 confection-0.1.4 cymem-2.0.8 langcodes-3.3.0 murmurhash-1.0.10 preshed-3.0.9 spacy-3.7.2 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.2.2 typer-0.9.0 wasabi-1.1.2 weasel-0.3.4\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/12.8 MB 187.9 kB/s eta 0:01:08\n",
      "     --------------------------------------- 0.0/12.8 MB 196.9 kB/s eta 0:01:05\n",
      "     --------------------------------------- 0.1/12.8 MB 403.5 kB/s eta 0:00:32\n",
      "      -------------------------------------- 0.2/12.8 MB 901.1 kB/s eta 0:00:14\n",
      "     - -------------------------------------- 0.5/12.8 MB 1.7 MB/s eta 0:00:08\n",
      "     --- ------------------------------------ 1.1/12.8 MB 3.1 MB/s eta 0:00:04\n",
      "     ----- ---------------------------------- 1.7/12.8 MB 4.2 MB/s eta 0:00:03\n",
      "     -------- ------------------------------- 2.9/12.8 MB 6.5 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 4.5/12.8 MB 9.4 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 6.0/12.8 MB 11.3 MB/s eta 0:00:01\n",
      "     ----------------------- ---------------- 7.6/12.8 MB 13.2 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 9.2/12.8 MB 14.7 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 10.5/12.8 MB 25.2 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 10.6/12.8 MB 24.2 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.8/12.8 MB 31.1 MB/s eta 0:00:01\n",
      "     --------------------------------------- 12.8/12.8 MB 27.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.7.1) (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.10.8)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.24.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2023.11.17)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.7.1\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zwmJUbxKCPjS"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchtext\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import timm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iu20gzLxCu2y"
   },
   "source": [
    "## 2. Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ZOxeYUBvCSki"
   },
   "outputs": [],
   "source": [
    "train_data = []\n",
    "train_set_path = 'vqa_coco_dataset/vaq2.0.TrainImages.txt'\n",
    "\n",
    "with open(train_set_path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        temp = line.split('\\t')\n",
    "        qa = temp[1].split('?')\n",
    "\n",
    "        if len(qa) == 3:\n",
    "            answer = qa[2].strip()\n",
    "        else:\n",
    "            answer = qa[1].strip()\n",
    "\n",
    "        data_sample = {\n",
    "            'image_path': temp[0][:-2],\n",
    "            'question': qa[0] + '?',\n",
    "            'answer': answer\n",
    "        }\n",
    "        train_data.append(data_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "EiZ7OwSfCrKa"
   },
   "outputs": [],
   "source": [
    "val_data = []\n",
    "val_set_path = 'vqa_coco_dataset/vaq2.0.DevImages.txt'\n",
    "\n",
    "with open(val_set_path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        temp = line.split('\\t')\n",
    "        qa = temp[1].split('?')\n",
    "\n",
    "        if len(qa) == 3:\n",
    "            answer = qa[2].strip()\n",
    "        else:\n",
    "            answer = qa[1].strip()\n",
    "\n",
    "        data_sample = {\n",
    "            'image_path': temp[0][:-2],\n",
    "            'question': qa[0] + '?',\n",
    "            'answer': answer\n",
    "        }\n",
    "        val_data.append(data_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ZoX0dQbjEx53"
   },
   "outputs": [],
   "source": [
    "test_data = []\n",
    "test_set_path = 'vqa_coco_dataset/vaq2.0.TestImages.txt'\n",
    "\n",
    "with open(test_set_path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        temp = line.split('\\t')\n",
    "        qa = temp[1].split('?')\n",
    "\n",
    "        if len(qa) == 3:\n",
    "            answer = qa[2].strip()\n",
    "        else:\n",
    "            answer = qa[1].strip()\n",
    "\n",
    "        data_sample = {\n",
    "            'image_path': temp[0][:-2],\n",
    "            'question': qa[0] + '?',\n",
    "            'answer': answer\n",
    "        }\n",
    "        test_data.append(data_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A_n5-R4NMqBx"
   },
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "_RqGo2gUNwLW"
   },
   "outputs": [],
   "source": [
    "eng = spacy.load(\"en_core_web_sm\") # Load the English model to tokenize English text\n",
    "\n",
    "def get_tokens(data_iter):\n",
    "    for sample in data_iter:\n",
    "        question = sample['question']\n",
    "\n",
    "        yield [token.text for token in eng.tokenizer(question)]\n",
    "\n",
    "\n",
    "vocab = build_vocab_from_iterator(\n",
    "    get_tokens(train_data),\n",
    "    min_freq=2,\n",
    "    specials= ['<pad>', '<sos>', '<eos>', '<unk>'],\n",
    "    special_first=True\n",
    ")\n",
    "vocab.set_default_index(vocab['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NDRHRaKyRiq6",
    "outputId": "d16b124c-2f1a-4f00-8ef4-0d5e0be84d88"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1678"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "G8cMLRR5Nyrm"
   },
   "outputs": [],
   "source": [
    "def tokenize(question, max_seq_len):\n",
    "    tokens = [token.text for token in eng.tokenizer(question)]\n",
    "    sequence = [vocab[token] for token in tokens]\n",
    "    if len(sequence) < max_seq_len:\n",
    "        sequence += [vocab['<pad>']] * (max_seq_len - len(sequence))\n",
    "    else:\n",
    "        sequence = sequence[:max_seq_len]\n",
    "\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GNfi1xqHTDgA",
    "outputId": "d79f65f7-7aea-443d-8f2c-2d3aea6be516"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 5, 7, 16, 21, 75, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_question = \"Is this a picture of an apple?\"\n",
    "max_seq_len = 20\n",
    "\n",
    "tokenize(example_question, max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d6Qf8EMA-gjK",
    "outputId": "e378185b-ecc9-471d-f386-2bf3079c448e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'yes', 1: 'no'}\n"
     ]
    }
   ],
   "source": [
    "classes = set([sample['answer'] for sample in train_data])\n",
    "classes_to_idx = {\n",
    "    cls_name: idx for idx, cls_name in enumerate(classes)\n",
    "}\n",
    "idx_to_classes = {\n",
    "    idx: cls_name for idx, cls_name in enumerate(classes)\n",
    "}\n",
    "print(idx_to_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9UznC-J7FVTf"
   },
   "source": [
    "## 4. Create Pytorch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "fXAFcSjnGlZF"
   },
   "outputs": [],
   "source": [
    "class VQADataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data,\n",
    "        classes_to_idx,\n",
    "        max_seq_len=20,\n",
    "        transform=None,\n",
    "        root_dir='vqa_coco_dataset/val2014-resised/'\n",
    "    ):\n",
    "        self.transform = transform\n",
    "        self.data = data\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.root_dir = root_dir\n",
    "        self.classes_to_idx = classes_to_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.root_dir, self.data[index]['image_path'])\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        question = self.data[index]['question']\n",
    "        question = tokenize(question, self.max_seq_len)\n",
    "        question = torch.tensor(question, dtype=torch.long)\n",
    "\n",
    "        label = self.data[index]['answer']\n",
    "        label = classes_to_idx[label]\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return img, question, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "AtRtdtYzrgeB"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "NmyFmD_GL-BQ"
   },
   "outputs": [],
   "source": [
    "train_dataset = VQADataset(\n",
    "    train_data,\n",
    "    classes_to_idx=classes_to_idx,\n",
    "    transform=transform\n",
    ")\n",
    "val_dataset = VQADataset(\n",
    "    val_data,\n",
    "    classes_to_idx=classes_to_idx,\n",
    "    transform=transform\n",
    ")\n",
    "test_dataset = VQADataset(\n",
    "    test_data,\n",
    "    classes_to_idx=classes_to_idx,\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "AToEIVctirQK"
   },
   "outputs": [],
   "source": [
    "train_batch_size = 128\n",
    "test_batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=train_batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=test_batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=test_batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fOcnB225J90K"
   },
   "source": [
    "## 5. Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "UwZNqfIvLmup"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mVQAModel\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m      4\u001b[0m         n_classes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m         dropout_prob\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m\n\u001b[0;32m     10\u001b[0m     ):\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;28msuper\u001b[39m(VQAModel, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class VQAModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_classes,\n",
    "        img_model_name='resnet50',\n",
    "        embeddding_dim=64,\n",
    "        n_layers=1,\n",
    "        hidden_size=128,\n",
    "        dropout_prob=0.2\n",
    "    ):\n",
    "        super(VQAModel, self).__init__()\n",
    "        self.image_encoder = timm.create_model(\n",
    "            img_model_name,\n",
    "            pretrained=True,\n",
    "            num_classes=hidden_size\n",
    "        )\n",
    "\n",
    "        self.embedding = nn.Embedding(len(vocab), embeddding_dim)\n",
    "        self.lstm1 = nn.LSTM(\n",
    "            input_size=embeddding_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=n_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        self.lstm2 = nn.LSTM(\n",
    "            input_size=hidden_size*3,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=n_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.fc = nn.Linear(hidden_size * 2, n_classes)\n",
    "\n",
    "    def forward(self, img, text):\n",
    "        img_features = self.image_encoder(img)\n",
    "\n",
    "        text_emb = self.embedding(text)\n",
    "        lstm_out, _ = self.lstm1(text_emb)\n",
    "\n",
    "        lstm_out = lstm_out[:, -1, :]\n",
    "\n",
    "        combined = torch.cat((img_features, lstm_out), dim=1)\n",
    "        x, _ = self.lstm2(combined)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "obxbBWAbkg2A"
   },
   "outputs": [],
   "source": [
    "n_classes = len(classes)\n",
    "img_model_name = 'resnet50'\n",
    "hidden_size = 128\n",
    "n_layers = 1\n",
    "embeddding_dim = 64\n",
    "dropout_prob = 0.2\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = VQAModel(\n",
    "    n_classes=n_classes,\n",
    "    img_model_name=img_model_name,\n",
    "    embeddding_dim=embeddding_dim,\n",
    "    n_layers=n_layers,\n",
    "    hidden_size=hidden_size,\n",
    "    dropout_prob=dropout_prob\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZzhJzxrGmWSO",
    "outputId": "13e3c3d3-f524-4335-82e5-5d37b33c66fe"
   },
   "outputs": [],
   "source": [
    "images, questions, labels = next(iter(train_loader))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    images = images.to(device)\n",
    "    questions = questions.to(device)\n",
    "    output = model(images, questions)\n",
    "    print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OmPEn5s-mjJe"
   },
   "source": [
    "## 6. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "pBIA8pH0rEHF"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for image, question, labels in dataloader:\n",
    "            image, question, labels = image.to(device), question.to(device), labels.to(device)\n",
    "            outputs = model(image, question)\n",
    "            loss = criterion(outputs, labels)\n",
    "            losses.append(loss.item())\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    loss = sum(losses) / len(losses)\n",
    "    acc = correct / total\n",
    "\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "6hj65HGor2pv"
   },
   "outputs": [],
   "source": [
    "lr = 1e-2\n",
    "epochs = 50\n",
    "\n",
    "scheduler_step_size = epochs * 0.6\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=lr\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer,\n",
    "    step_size=scheduler_step_size,\n",
    "    gamma=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z5Qmw6efr5HG",
    "outputId": "e75bdfa0-e348-4a79-99c8-4318dd76e5ff"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_losses, val_losses \u001b[38;5;241m=\u001b[39m fit(\n\u001b[0;32m      2\u001b[0m     model,\n\u001b[0;32m      3\u001b[0m     train_loader,\n\u001b[0;32m      4\u001b[0m     val_loader,\n\u001b[0;32m      5\u001b[0m     criterion,\n\u001b[0;32m      6\u001b[0m     optimizer,\n\u001b[0;32m      7\u001b[0m     scheduler,\n\u001b[0;32m      8\u001b[0m     device,\n\u001b[0;32m      9\u001b[0m     epochs\n\u001b[0;32m     10\u001b[0m )\n",
      "Cell \u001b[1;32mIn[42], line 24\u001b[0m, in \u001b[0;36mfit\u001b[1;34m(model, train_loader, val_loader, criterion, optimizer, scheduler, device, epochs)\u001b[0m\n\u001b[0;32m     21\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 24\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(images, questions)\n\u001b[0;32m     25\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     26\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[38], line 37\u001b[0m, in \u001b[0;36mVQAModel.forward\u001b[1;34m(self, img, text)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, img, text):\n\u001b[1;32m---> 37\u001b[0m     img_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_encoder(img)\n\u001b[0;32m     39\u001b[0m     text_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(text)\n\u001b[0;32m     40\u001b[0m     lstm_out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm1(text_emb)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\timm\\models\\resnet.py:578\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 578\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_features(x)\n\u001b[0;32m    579\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_head(x)\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\timm\\models\\resnet.py:568\u001b[0m, in \u001b[0;36mResNet.forward_features\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    566\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n\u001b[0;32m    567\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x)\n\u001b[1;32m--> 568\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer4(x)\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\timm\\models\\resnet.py:221\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    218\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(x)\n\u001b[0;32m    219\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact1(x)\n\u001b[1;32m--> 221\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)\n\u001b[0;32m    222\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(x)\n\u001b[0;32m    223\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_block(x)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    457\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = fit(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    device,\n",
    "    epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "xIobHWIptBQm",
    "outputId": "5784c533-8181-4028-e5af-61e6bfe51cd8"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "ax[0].plot(train_losses)\n",
    "ax[0].set_title('Training Loss')\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[1].plot(val_losses, color='orange')\n",
    "ax[1].set_title('Val Loss')\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].set_ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPFgeiArr6zp"
   },
   "source": [
    "## 7. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "psvbHQpis5bm",
    "outputId": "b5b9ef47-2cdd-4332-f126-33ed4963ac10"
   },
   "outputs": [],
   "source": [
    "val_loss, val_acc = evaluate(\n",
    "    model,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    device\n",
    ")\n",
    "test_loss, test_acc = evaluate(\n",
    "    model,\n",
    "    test_loader,\n",
    "    criterion,\n",
    "    device\n",
    ")\n",
    "\n",
    "print('Evaluation on val/test dataset')\n",
    "print('Val accuracy: ', val_acc)\n",
    "print('Test accuracy: ', test_acc)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
